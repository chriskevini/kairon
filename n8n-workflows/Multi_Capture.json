{
  "name": "Multi_Capture",
  "nodes": [
    {
      "parameters": {
        "inputSource": "passthrough"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        -1600,
        936
      ],
      "id": "trigger-multi-extract",
      "name": "execute_workflow_trigger"
    },
    {
      "parameters": {
        "jsCode": "// Prepare for multi-capture\nconst ctx = $json.ctx;\n\nreturn [{\n  json: {\n    ctx: ctx,\n    inference_start: Date.now()\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1376,
        840
      ],
      "id": "prepare-extraction",
      "name": "prepare_capture"
    },
    {
      "parameters": {
        "method": "DELETE",
        "url": "=https://discord.com/api/v10/channels/{{ $json.ctx.event.channel_id }}/messages/{{ $json.ctx.event.message_id }}/reactions/\ud83d\udd35/@me",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "discordBotApi",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1376,
        1032
      ],
      "id": "remove-blue-reaction",
      "name": "remove_\ud83d\udd35_reaction",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 1000,
      "credentials": {
        "discordBotApi": {
          "name": "Discord Bot account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are an extraction agent for a life-tracking system. Analyze the message and extract all relevant items.\n\n## Message to Analyze\n\n\"{{ $json.ctx.event.clean_text }}\"\n\n## Extraction Types\n\n### Activity (what the user is doing NOW)\nExtract if the message describes a CURRENT or RECENT action by the user.\n- **Categories:** work, leisure, study, health, sleep, relationships, admin\n- **Indicators:** \"I am\", \"I'm\", \"-ing verbs\", \"just did\", present/recent past tense\n\n### Note (observation, insight, or fact worth remembering)\nExtract if the message contains knowledge, observations, or reflections.\n- **Categories:** reflection (about self), fact (about world/others)\n- **Indicators:** observations about things/people, realizations, ideas, decisions\n\n### Todo (actionable task to complete)\nExtract if the message contains a clear task to do later.\n- **Priority:** high, medium, low\n- **Indicators:** \"need to\", \"should\", \"have to\", \"TODO\", future tasks\n\n## Key Rules\n\n1. A message can have 0, 1, 2, or 3 extractions\n2. Set confidence 0.0-1.0 based on how clearly the message indicates each type\n3. Only include extractions with confidence >= 0.5\n4. Prefer fewer high-confidence extractions over many low-confidence ones\n5. Activity describes what I'M doing; Note describes observations about anything else\n\n## Output Format\n\nOutput ONLY valid JSON, no explanation:\n\n{\"activity\": {\"category\": \"work\", \"description\": \"debugging auth\", \"confidence\": 0.92}, \"note\": {\"category\": \"reflection\", \"text\": \"noticed pattern in logs\", \"confidence\": 0.78}, \"todo\": null}",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        -1152,
        840
      ],
      "id": "multi-extractor",
      "name": "multi_capturer"
    },
    {
      "parameters": {
        "model": "xiaomi/mimo-v2-flash:free",
        "options": {
          "timeout": 15000
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        -1144,
        1064
      ],
      "id": "mimo-v2-flash",
      "name": "mimo_v2_flash",
      "credentials": {
        "openRouterApi": {
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "model": "nvidia/nemotron-nano-9b-v2:free",
        "options": {
          "timeout": 15000
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        -1016,
        1064
      ],
      "id": "nemotron-nano-9b",
      "name": "nemotron_nano_9b",
      "credentials": {
        "openRouterApi": {
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse LLM response, filter by confidence, build trace query\nconst EMOJI = { activity: '\ud83d\udd18', note: '\ud83d\udcdd', todo: '\u2705' };\nconst CONFIDENCE_THRESHOLD = 0.5;\n\nconst llmText = $json.text?.trim() || '';\nconst prepareItem = $('Prepare Capture').first().json;\nconst ctx = prepareItem.ctx;\nconst durationMs = Date.now() - prepareItem.inference_start;\n\n// Full rendered prompt (template + input)\nconst fullPrompt = `You are an extraction agent for a life-tracking system. Analyze the message and extract all relevant items.\n\n## Message to Analyze\n\n\"${ctx.event.clean_text}\"\n\n## Extraction Types\n\n### Activity (what the user is doing NOW)\nExtract if the message describes a CURRENT or RECENT action by the user.\n- **Categories:** work, leisure, study, health, sleep, relationships, admin\n- **Indicators:** \"I am\", \"I'm\", \"-ing verbs\", \"just did\", present/recent past tense\n\n### Note (observation, insight, or fact worth remembering)\nExtract if the message contains knowledge, observations, or reflections.\n- **Categories:** reflection (about self), fact (about world/others)\n- **Indicators:** observations about things/people, realizations, ideas, decisions\n\n### Todo (actionable task to complete)\nExtract if the message contains a clear task to do later.\n- **Priority:** high, medium, low\n- **Indicators:** \"need to\", \"should\", \"have to\", \"TODO\", future tasks\n\n## Key Rules\n\n1. A message can have 0, 1, 2, or 3 extractions\n2. Set confidence 0.0-1.0 based on how clearly the message indicates each type\n3. Only include extractions with confidence >= 0.5\n4. Prefer fewer high-confidence extractions over many low-confidence ones\n5. Activity describes what I'M doing; Note describes observations about anything else\n\n## Output Format\n\nOutput ONLY valid JSON, no explanation:\n\n{\"activity\": {\"category\": \"work\", \"description\": \"debugging auth\", \"confidence\": 0.92}, \"note\": {\"category\": \"reflection\", \"text\": \"noticed pattern in logs\", \"confidence\": 0.78}, \"todo\": null}`;\n\n// Format trace_chain for PostgreSQL\nconst traceChain = ctx.event.trace_chain || [];\nconst traceChainPg = '{' + traceChain.join(',') + '}';\n\n// Parse JSON from LLM output\nlet parsed = { activity: null, note: null, todo: null };\nlet parseError = null;\n\ntry {\n  let jsonStr = llmText;\n  const codeBlock = llmText.match(/```(?:json)?\\s*([\\s\\S]*?)```/);\n  if (codeBlock) jsonStr = codeBlock[1].trim();\n  const objMatch = jsonStr.match(/\\{[\\s\\S]*\\}/);\n  if (objMatch) jsonStr = objMatch[0];\n  parsed = JSON.parse(jsonStr);\n} catch (e) {\n  parseError = e.message;\n}\n\n// Build captures array\nconst captures = [];\nconst emojis = [];\n\nif (parsed.activity?.confidence >= CONFIDENCE_THRESHOLD) {\n  captures.push({\n    type: 'activity',\n    emoji: EMOJI.activity,\n    data: {\n      timestamp: new Date().toISOString(),\n      category: parsed.activity.category || 'work',\n      description: parsed.activity.description || ctx.event.clean_text,\n      message_url: ctx.event.message_url,\n      confidence: parsed.activity.confidence\n    }\n  });\n  emojis.push(EMOJI.activity);\n}\n\nif (parsed.note?.confidence >= CONFIDENCE_THRESHOLD) {\n  captures.push({\n    type: 'note',\n    emoji: EMOJI.note,\n    data: {\n      timestamp: new Date().toISOString(),\n      category: parsed.note.category || 'reflection',\n      text: parsed.note.text || ctx.event.clean_text,\n      message_url: ctx.event.message_url,\n      confidence: parsed.note.confidence\n    }\n  });\n  emojis.push(EMOJI.note);\n}\n\nif (parsed.todo?.confidence >= CONFIDENCE_THRESHOLD) {\n  captures.push({\n    type: 'todo',\n    emoji: EMOJI.todo,\n    data: {\n      timestamp: new Date().toISOString(),\n      priority: parsed.todo.priority || 'medium',\n      text: parsed.todo.text || ctx.event.clean_text,\n      message_url: ctx.event.message_url,\n      confidence: parsed.todo.confidence\n    }\n  });\n  emojis.push(EMOJI.todo);\n}\n\n// Fallback: if nothing captured, create low-confidence note\nif (captures.length === 0) {\n  captures.push({\n    type: 'note',\n    emoji: EMOJI.note,\n    data: {\n      timestamp: new Date().toISOString(),\n      category: 'reflection',\n      text: ctx.event.clean_text,\n      message_url: ctx.event.message_url,\n      confidence: 0.3\n    }\n  });\n  emojis.push(EMOJI.note);\n}\n\n// Pre-stringify the result for postgres jsonb\nconst resultJson = JSON.stringify(captures.map(c => ({ type: c.type, confidence: c.data.confidence })));\n\n// Return with ctx.db_queries for Execute_Queries\nreturn [{\n  json: {\n    ctx: {\n      ...ctx,\n      db_queries: [{\n        key: 'trace',\n        sql: `INSERT INTO traces (event_id, step_name, data, trace_chain)\nVALUES (\n  $1::uuid,\n  'multi_capture',\n  jsonb_build_object(\n    'prompt', $2,\n    'input', jsonb_build_object('text', $3),\n    'completion', $4,\n    'result', $5::jsonb,\n    'model', 'xiaomi/mimo-v2-flash:free',\n    'duration_ms', $6::integer,\n    'capture_count', $7::integer\n  ),\n  $8::uuid[]\n)\nRETURNING id, trace_chain || id AS updated_trace_chain;`,\n        params: [\n          ctx.event.event_id,\n          fullPrompt,\n          ctx.event.clean_text,\n          llmText,\n          resultJson,\n          durationMs,\n          captures.length,\n          traceChainPg\n        ]\n      }]\n    },\n    captures,\n    emojis,\n    total_captures: captures.length,\n    raw_response: llmText,\n    parse_error: parseError,\n    duration_ms: durationMs\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -800,
        840
      ],
      "id": "parse-and-split",
      "name": "parse_response"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "PLACEHOLDER_WILL_BE_FIXED_BY_DEPLOY",
          "mode": "list",
          "cachedResultName": "Execute_Queries"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {}
        },
        "options": {}
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        -576,
        840
      ],
      "id": "store-llm-trace",
      "name": "store_llm_trace"
    },
    {
      "parameters": {
        "jsCode": "// Split captures into individual items for projection storage\n// Input: Store LLM Trace result (ctx with db.trace)\n// Output: One item per capture, each with trace_id attached\n\nconst ctx = $json.ctx;\nconst parseResult = $('Parse Response').first().json;\n\nconst llmTraceId = ctx.db?.trace?.row?.id;\nconst updatedTraceChain = ctx.db?.trace?.row?.updated_trace_chain || [];\nconst updatedTraceChainPg = '{' + updatedTraceChain.join(',') + '}';\n\n// Split captures array into individual items, each with its own db_queries\nreturn parseResult.captures.map(capture => ({\n  json: {\n    ctx: {\n      ...ctx,\n      db_queries: [{\n        key: 'projection',\n        sql: `INSERT INTO projections (trace_id, event_id, trace_chain, projection_type, data, status, timezone)\nVALUES (\n  $1::uuid,\n  $2::uuid,\n  $3::uuid[],\n  $4,\n  $5::jsonb,\n  'auto_confirmed',\n  $6\n)\nRETURNING *;`,\n        params: [\n          llmTraceId,\n          ctx.event.event_id,\n          updatedTraceChainPg,\n          capture.type,\n          JSON.stringify(capture.data),\n          ctx.event.timezone\n        ]\n      }]\n    },\n    capture\n  }\n}));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -352,
        840
      ],
      "id": "prepare-projections",
      "name": "split_captures"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "PLACEHOLDER_WILL_BE_FIXED_BY_DEPLOY",
          "mode": "list",
          "cachedResultName": "Execute_Queries"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {}
        },
        "options": {}
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        128,
        840
      ],
      "id": "store-projection",
      "name": "store_projection"
    },
    {
      "parameters": {
        "jsCode": "// Collect results for logging with standard emojis\nconst parseResult = $('Parse Response').first().json;\n\n// Standard emoji mapping\nconst typeEmojis = {\n  'activity': '\ud83d\udd18',\n  'note': '\ud83d\udcdd',\n  'todo': '\ud83d\udd32'\n};\n\n// Map capture types to standard emojis\nconst emojis = parseResult.captures.map(c => typeEmojis[c.type] || '\ud83d\udce6');\n\n// Build verbose config query\nreturn [{\n  json: {\n    ctx: {\n      ...parseResult.ctx,\n      db_queries: [{\n        key: 'verbose_config',\n        sql: `SELECT value FROM config WHERE key = 'verbose'`,\n        params: []\n      }]\n    },\n    emojis: emojis,\n    duration_ms: parseResult.duration_ms,\n    projection_count: parseResult.total_captures\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -576,
        1032
      ],
      "id": "collect-results",
      "name": "collect_results"
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "=https://discord.com/api/v10/channels/{{ $json.ctx.event.channel_id }}/messages/{{ $json.ctx.event.message_id }}/reactions/{{ $json.emoji }}/@me",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "discordBotApi",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -128,
        528
      ],
      "id": "add-emoji-reactions",
      "name": "add_emoji_reactions",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 1000,
      "credentials": {
        "discordBotApi": {
          "name": "Discord Bot account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "resource": "message",
        "guildId": {
          "__rl": true,
          "value": "={{ $json.ctx.event.guild_id }}",
          "mode": "id"
        },
        "channelId": {
          "__rl": true,
          "value": "={{ $env.DISCORD_CHANNEL_KAIRON_LOGS }}",
          "mode": "id"
        },
        "content": "={{ $json.ctx.event.clean_text }} {{ $json.duration_ms }}ms \u27a1\ufe0f {{ $json.emojis.join(' ') }}",
        "options": {}
      },
      "type": "n8n-nodes-base.discord",
      "typeVersion": 2,
      "position": [
        -352,
        1224
      ],
      "id": "log-to-kairon-logs",
      "name": "log_to_kairon_logs",
      "webhookId": "multi-capture-log",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 1000,
      "credentials": {
        "discordBotApi": {
          "name": "Discord Bot account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "amount": 1
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        96,
        552
      ],
      "id": "wait-rate-limit",
      "name": "wait_1s",
      "webhookId": "471830ad-77d3-4266-9eca-bf75cfee85a2"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        -352,
        552
      ],
      "id": "2741faa1-e8ab-4588-b3b5-bc67839680a3",
      "name": "loop_over_items"
    },
    {
      "parameters": {
        "jsCode": "// Convert emojis array to individual items for batch processing\nconst parseResult = $('Parse Response').first().json;\n\n// Standard emoji mapping\nconst typeEmojis = {\n  'activity': '\ud83d\udd18',\n  'note': '\ud83d\udcdd',\n  'todo': '\ud83d\udd32'\n};\n\n// Map capture types to standard emojis\nconst emojis = parseResult.captures.map(c => typeEmojis[c.type] || '\ud83d\udce6');\n\nreturn emojis.map(emoji => ({\n  json: {\n    ctx: parseResult.ctx,\n    emoji: emoji\n  }\n}));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -576,
        552
      ],
      "id": "prepare-emoji-items",
      "name": "prepare_emoji_items"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "PLACEHOLDER_WILL_BE_FIXED_BY_DEPLOY",
          "mode": "list",
          "cachedResultName": "Execute_Queries"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {}
        },
        "options": {}
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        -352,
        1032
      ],
      "id": "query-verbose-setting",
      "name": "query_verbose_setting"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "f55070f3-80b6-4076-a05d-6799052b6555",
              "leftValue": "={{ $json.ctx.verbose }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        96,
        1032
      ],
      "id": "if-verbose-true",
      "name": "if_verbose_true"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "PLACEHOLDER_WILL_BE_FIXED_BY_DEPLOY",
          "mode": "list",
          "cachedResultName": "Show_Projection_Details"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "ctx": "={{ $json.ctx }}"
          }
        },
        "options": {
          "waitForSubWorkflow": false
        }
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        320,
        1032
      ],
      "id": "trigger-show-details",
      "name": "trigger_show_details"
    },
    {
      "parameters": {
        "jsCode": "// Merge verbose config result into ctx\nconst collectResults = $('Collect Results').first().json;\nconst ctx = $json.ctx;\nconst verboseValue = ctx.db?.verbose_config?.row?.value;\n\nreturn [{\n  json: {\n    ctx: {\n      ...ctx,\n      verbose: verboseValue === 'true' || verboseValue === true\n    },\n    emojis: collectResults.emojis,\n    duration_ms: collectResults.duration_ms,\n    projection_count: collectResults.projection_count\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -128,
        1032
      ],
      "id": "merge-ctx-verbose",
      "name": "merge_ctx_for_verbose"
    },
    {
      "parameters": {
        "jsCode": "// Extract text for embedding from projection data\nconst ctx = $json.ctx;\nconst projection = ctx.db?.projection?.row || {};\nconst data = projection.data || {};\nconst embeddingText = data.description || data.text || '';\n\nreturn [{\n  json: {\n    projection_id: projection.id,\n    embedding_text: embeddingText\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        352,
        840
      ],
      "id": "prepare-embedding-text",
      "name": "prepare_embedding_text"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $env.EMBEDDING_SERVICE_URL }}/embed",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"texts\": [{{ JSON.stringify($json.embedding_text || '') }}]\n}",
        "options": {
          "timeout": 10000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        576,
        840
      ],
      "id": "embed-projection-text",
      "name": "embed_projection_text",
      "continueOnFail": true
    },
    {
      "parameters": {
        "jsCode": "// Build embedding insert query for Execute_Queries\nconst prepareData = $(\"Prepare Embedding Text\").first().json;\nconst embeddings = $json.embeddings;\n\n// Check if we have a valid embedding\nif (!embeddings || !embeddings[0]) {\n  // Return a pass-through item to keep the loop going\n  return [{\n    json: {\n      ctx: {\n        ...($json.ctx || {}),\n        db_queries: []  // Empty queries = no-op in Execute_Queries\n      }\n    }\n  }];\n}\n\nconst embeddingVector = \"[\" + embeddings[0].join(\",\") + \"]\";\n\nreturn [{\n  json: {\n    ctx: {\n      ...($json.ctx || {}),\n      db_queries: [{\n        key: \"embedding\",\n        sql: `-- Insert embedding for the projection (fire-and-forget)\nINSERT INTO embeddings (projection_id, model, embedding_data, embedded_text, embedding)\nSELECT \n  $1::uuid,\n  \"all-MiniLM-L6-v2\",\n  \"{}\",\n  $2,\n  $3::vector\nWHERE $3 IS NOT NULL\nON CONFLICT DO NOTHING;`,\n        params: [\n          prepareData.projection_id,\n          prepareData.embedding_text,\n          embeddingVector\n        ]\n      }]\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        800,
        840
      ],
      "id": "build-embedding-query",
      "name": "build_embedding_query"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "PLACEHOLDER_WILL_BE_FIXED_BY_DEPLOY",
          "mode": "list",
          "cachedResultName": "Execute_Queries"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {}
        },
        "options": {}
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        1024,
        840
      ],
      "id": "insert-embedding",
      "name": "insert_embedding",
      "continueOnFail": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        -128,
        840
      ],
      "id": "projection-loop",
      "name": "projection_loop"
    }
  ],
  "connections": {
    "execute_workflow_trigger": {
      "main": [
        [
          {
            "node": "prepare_capture",
            "type": "main",
            "index": 0
          },
          {
            "node": "remove_\ud83d\udd35_reaction",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "prepare_capture": {
      "main": [
        [
          {
            "node": "multi_capturer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "multi_capturer": {
      "main": [
        [
          {
            "node": "parse_response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "store_llm_trace": {
      "main": [
        [
          {
            "node": "split_captures",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "store_projection": {
      "main": [
        [
          {
            "node": "prepare_embedding_text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "prepare_embedding_text": {
      "main": [
        [
          {
            "node": "embed_projection_text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "embed_projection_text": {
      "main": [
        [
          {
            "node": "build_embedding_query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "build_embedding_query": {
      "main": [
        [
          {
            "node": "insert_embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "collect_results": {
      "main": [
        [
          {
            "node": "log_to_kairon_logs",
            "type": "main",
            "index": 0
          },
          {
            "node": "query_verbose_setting",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "add_emoji_reactions": {
      "main": [
        [
          {
            "node": "wait_1s",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "mimo_v2_flash": {
      "ai_languageModel": [
        [
          {
            "node": "multi_capturer",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "nemotron_nano_9b": {
      "ai_languageModel": [
        [
          {
            "node": "multi_capturer",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "wait_1s": {
      "main": [
        [
          {
            "node": "loop_over_items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "loop_over_items": {
      "main": [
        [],
        [
          {
            "node": "add_emoji_reactions",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "parse_response": {
      "main": [
        [
          {
            "node": "store_llm_trace",
            "type": "main",
            "index": 0
          },
          {
            "node": "collect_results",
            "type": "main",
            "index": 0
          },
          {
            "node": "prepare_emoji_items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "split_captures": {
      "main": [
        [
          {
            "node": "projection_loop",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "prepare_emoji_items": {
      "main": [
        [
          {
            "node": "loop_over_items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "log_to_kairon_logs": {
      "main": [
        []
      ]
    },
    "query_verbose_setting": {
      "main": [
        [
          {
            "node": "merge_ctx_for_verbose",
            "index": 0,
            "type": "main"
          }
        ]
      ]
    },
    "if_verbose_true": {
      "main": [
        [
          {
            "node": "trigger_show_details",
            "index": 0,
            "type": "main"
          }
        ]
      ]
    },
    "merge_ctx_for_verbose": {
      "main": [
        [
          {
            "node": "if_verbose_true",
            "index": 0,
            "type": "main"
          }
        ]
      ]
    },
    "projection_loop": {
      "main": [
        [],
        [
          {
            "node": "store_projection",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "insert_embedding": {
      "main": [
        [
          {
            "node": "projection_loop",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "availableInMCP": false,
    "errorWorkflow": "JOXLqn9TTznBdo7Q"
  },
  "staticData": null,
  "meta": null,
  "active": false
}