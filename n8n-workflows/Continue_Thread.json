{
  "name": "Continue_Thread",
  "nodes": [
    {
      "parameters": {
        "inputSource": "passthrough"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        0,
        400
      ],
      "id": "trigger",
      "name": "Execute Workflow Trigger"
    },
    {
      "parameters": {
        "resource": "message",
        "operation": "react",
        "guildId": {
          "__rl": true,
          "value": "={{ $json.ctx.event.guild_id }}",
          "mode": "id"
        },
        "channelId": {
          "__rl": true,
          "value": "={{ $json.ctx.event.channel_id }}",
          "mode": "id"
        },
        "messageId": "={{ $json.ctx.event.message_id }}",
        "emoji": "=ðŸ’­"
      },
      "type": "n8n-nodes-base.discord",
      "typeVersion": 2,
      "position": [
        224,
        200
      ],
      "id": "react-thinking",
      "name": "React with ðŸ’­",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 1000,
      "credentials": {
        "discordBotApi": {
          "id": "hvetTjtpeKFB1V0I",
          "name": "Discord Bot account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "method": "DELETE",
        "url": "=https://discord.com/api/v10/channels/{{ $json.ctx.event.channel_id }}/messages/{{ $json.ctx.event.message_id }}/reactions/ðŸ”µ/@me",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "discordBotApi",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        224,
        600
      ],
      "id": "remove-blue-reaction",
      "name": "Remove ðŸ”µ Reaction",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 1000,
      "credentials": {
        "discordBotApi": {
          "id": "hvetTjtpeKFB1V0I",
          "name": "Discord Bot account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// Prepare all queries for thread continuation context\nconst ctx = $json.ctx;\n\nreturn [{\n  json: {\n    ctx: {\n      ...ctx,\n      db_queries: [\n        {\n          key: 'history',\n          sql: \"SELECT timestamp, role, text FROM thread_history WHERE thread_id = $1 AND NOT (role = 'user' AND text = $2) ORDER BY timestamp ASC LIMIT 20\",\n          params: [ctx.event.thread_id, ctx.event.clean_text]\n        },\n        {\n          key: 'north_star',\n          sql: \"SELECT value FROM config WHERE key = 'north_star'\"\n        },\n        {\n          key: 'activities',\n          sql: `SELECT \n            (data->>'timestamp')::timestamptz as timestamp,\n            data->>'category' as category,\n            data->>'description' as description\n          FROM projections\n          WHERE projection_type = 'activity'\n            AND status IN ('auto_confirmed', 'confirmed')\n          ORDER BY (data->>'timestamp')::timestamptz DESC\n          LIMIT 20`\n        },\n        {\n          key: 'notes',\n          sql: `SELECT \n            (data->>'timestamp')::timestamptz as timestamp,\n            data->>'category' as category,\n            data->>'text' as text\n          FROM projections\n          WHERE projection_type = 'note'\n            AND status IN ('auto_confirmed', 'confirmed')\n          ORDER BY (data->>'timestamp')::timestamptz DESC\n          LIMIT 10`\n        }\n      ],\n      llm: {\n        inference_start: Date.now()\n      }\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        224,
        400
      ],
      "id": "prepare-queries",
      "name": "Prepare All Queries"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "UpiUvzlgVuMdYsnp",
          "mode": "id"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "ctx": "={{ $json.ctx }}"
          }
        },
        "options": {
          "waitForSubWorkflow": true
        }
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        448,
        400
      ],
      "id": "query-db",
      "name": "Query DB"
    },
    {
      "parameters": {
        "jsCode": "// Build LLM context from batch query results\nconst ctx = $json.ctx;\n\n// Extract results from ctx.db (keyed by query name)\nconst history = (ctx.db?.history?.results || []).map(h => ({ role: h.role, text: h.text }));\nconst northStar = ctx.db?.north_star?.results?.[0]?.value || '(not set)';\nconst activities = (ctx.db?.activities?.results || []).map(a => ({\n  timestamp: a.timestamp,\n  category: a.category,\n  description: a.description\n}));\nconst notes = (ctx.db?.notes?.results || []).map(n => ({\n  timestamp: n.timestamp,\n  category: n.category,\n  text: n.text\n}));\n\nreturn [{\n  json: {\n    ctx: {\n      ...ctx,\n      llm: {\n        ...ctx.llm,\n        history: history,\n        north_star: northStar,\n        activities: activities,\n        notes: notes\n      }\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        672,
        400
      ],
      "id": "build-context",
      "name": "Build LLM Context"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are an AI life coach helping the user reflect, plan, and think deeply.\n\n## Context Available\n\n**User's Guiding Principle:** {{ $json.ctx.llm.north_star }}\n\nKeep this in mind when helping them, but don't mention it unless directly relevant to the conversation.\n\n**Recent Activities (Last 20)**\n{{ $json.ctx.llm.activities.map(act => `${DateTime.fromISO(act.timestamp).format(\"yyyy-MM-dd hh:mm\")} - ${act.description}`).join('\\n') }}\n\n**Recent Notes (Last 10)**\n{{ $json.ctx.llm.notes.map(n => `[${n.category}] ${n.text}`).join('\\n') }}\n\n## Instructions\n\n1. **Consider the full context**: conversation history, activities, and notes\n2. **Provide grounded insights**: Reference specific activities or notes when relevant\n3. **Be conversational**: This is an ongoing dialogue, not a new conversation\n4. **Ask clarifying questions**: Help them think deeper when appropriate\n5. **Be concise**: 3-5 sentences, respect their time\n6. **Don't force connections**: Only mention the guiding principle if it's naturally relevant to what they're asking about\n\n## Style\n- Warm and supportive\n- Natural and conversational\n- Focus on what they're asking, not on fitting everything into a grand narrative\n\n## Conversation History\n{{ $json.ctx.llm.history.map(msg => `${msg.role.toUpperCase()}: ${msg.text}`).join('\\n\\n') }}\n\nUSER: {{ $json.ctx.event.clean_text }}\n\nASSISTANT:",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        896,
        400
      ],
      "id": "generate-response",
      "name": "Generate Response"
    },
    {
      "parameters": {
        "model": "xiaomi/mimo-v2-flash:free",
        "options": {
          "temperature": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        904,
        624
      ],
      "id": "mimo-v2-flash",
      "name": "mimo-v2-flash",
      "credentials": {
        "openRouterApi": {
          "id": "r79IBN16aZtPIN8T",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "model": "nvidia/nemotron-nano-9b-v2:free",
        "options": {
          "temperature": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        1032,
        624
      ],
      "id": "nemotron-nano-9b",
      "name": "nemotron-nano-9b",
      "credentials": {
        "openRouterApi": {
          "id": "r79IBN16aZtPIN8T",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "llm-completion",
              "name": "ctx.llm.completion_text",
              "value": "={{ $json.text }}",
              "type": "string"
            }
          ]
        },
        "options": {
          "includeOtherFields": true
        }
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1120,
        400
      ],
      "id": "set-llm-completion",
      "name": "Set LLM Completion"
    },
    {
      "parameters": {
        "resource": "message",
        "guildId": {
          "__rl": true,
          "value": "={{ $json.ctx.event.guild_id }}",
          "mode": "id"
        },
        "channelId": {
          "__rl": true,
          "value": "={{ $json.ctx.event.thread_id }}",
          "mode": "id"
        },
        "content": "={{ $json.ctx.llm.completion_text }}",
        "options": {}
      },
      "type": "n8n-nodes-base.discord",
      "typeVersion": 2,
      "position": [
        1344,
        200
      ],
      "id": "post-to-thread",
      "name": "Post to Thread",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 1000,
      "credentials": {
        "discordBotApi": {
          "id": "hvetTjtpeKFB1V0I",
          "name": "Discord Bot account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Prepare trace data after LLM inference using Write_DB batch\nconst ctx = $json.ctx || {};\nconst response = ctx.llm?.completion_text || '';\nconst inferenceStart = ctx.llm?.inference_start || Date.now();\nconst durationMs = Date.now() - inferenceStart;\n\n// Build filled prompt (reconstructed from template)\nconst promptText = `You are an AI life coach helping the user reflect, plan, and think deeply.\n\n## Context Available\n\n**User's Guiding Principle:** ${ctx.llm?.north_star || '(not set)'}\n\n**Recent Activities (Last 20)**\n${(ctx.llm?.activities || []).map(act => `${act.timestamp} - ${act.description}`).join('\\n')}\n\n**Recent Notes (Last 10)**\n${(ctx.llm?.notes || []).map(n => `[${n.category}] ${n.text}`).join('\\n')}\n\n## Conversation History\n${(ctx.llm?.history || []).map(msg => `${msg.role.toUpperCase()}: ${msg.text}`).join('\\n\\n')}\n\nUSER: ${ctx.event?.clean_text || ''}\n\nASSISTANT:`;\n\n// Format trace_chain for PostgreSQL uuid[] type\nconst traceChain = ctx.event?.trace_chain || [];\nconst traceChainPg = '{' + traceChain.join(',') + '}';\n\nconst eventId = ctx.event?.event_id;\nconst threadId = ctx.event?.thread_id;\nconst timestamp = ctx.event?.timestamp;\nconst timezone = ctx.event?.timezone;\nconst cleanText = ctx.event?.clean_text || '';\nconst historyLength = (ctx.llm?.history || []).length;\n\n// Build trace data JSON\nconst traceDataJson = JSON.stringify({\n  input: { text: cleanText, thread_id: threadId, history_length: historyLength },\n  prompt: promptText,\n  completion: response,\n  result: { \n    response_length: response.length,\n    referenced_activities: (ctx.llm?.activities || []).length,\n    referenced_notes: (ctx.llm?.notes || []).length\n  },\n  model: 'xiaomi/mimo-v2-flash:free',\n  duration_ms: durationMs\n});\n\n// Build projection data JSON\nconst projectionDataJson = JSON.stringify({\n  thread_id: threadId,\n  response_text: response,\n  role: 'assistant',\n  timestamp: timestamp\n});\n\nreturn [{\n  json: {\n    ctx: {\n      ...ctx,\n      db_writes: [\n        {\n          key: 'trace',\n          sql: `WITH new_trace AS (\n            INSERT INTO traces (event_id, step_name, data, trace_chain)\n            VALUES ($1::uuid, 'thread_response', $2::jsonb, $3::uuid[])\n            RETURNING id\n          )\n          SELECT new_trace.id as trace_id, $3::uuid[] || new_trace.id as updated_trace_chain\n          FROM new_trace`,\n          params: [eventId, traceDataJson, traceChainPg]\n        },\n        {\n          key: 'projection',\n          sql: `INSERT INTO projections (event_id, trace_id, trace_chain, projection_type, status, data, timezone)\n                VALUES ($1::uuid, $2::uuid, $3::uuid[], 'thread_response', 'auto_confirmed', $4::jsonb, $5)\n                RETURNING id`,\n          params: [eventId, '$results.trace.row.trace_id', '$results.trace.row.updated_trace_chain', projectionDataJson, timezone]\n        }\n      ]\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1344,
        400
      ],
      "id": "prepare-trace-data",
      "name": "Prepare Trace Data"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "mode": "id",
          "value": "zgJX3AbUNUvDJa48"
        }
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.2,
      "position": [
        1568,
        400
      ],
      "id": "write-trace-and-projection",
      "name": "Write Trace + Projection"
    }
  ],
  "connections": {
    "Execute Workflow Trigger": {
      "main": [
        [
          {
            "node": "React with ðŸ’­",
            "type": "main",
            "index": 0
          },
          {
            "node": "Prepare All Queries",
            "type": "main",
            "index": 0
          },
          {
            "node": "Remove ðŸ”µ Reaction",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare All Queries": {
      "main": [
        [
          {
            "node": "Query DB",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query DB": {
      "main": [
        [
          {
            "node": "Build LLM Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build LLM Context": {
      "main": [
        [
          {
            "node": "Generate Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Response": {
      "main": [
        [
          {
            "node": "Set LLM Completion",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "mimo-v2-flash": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Response",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "nemotron-nano-9b": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Response",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Set LLM Completion": {
      "main": [
        [
          {
            "node": "Post to Thread",
            "type": "main",
            "index": 0
          },
          {
            "node": "Prepare Trace Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Trace Data": {
      "main": [
        [
          {
            "node": "Write Trace + Projection",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "availableInMCP": false,
    "errorWorkflow": "JOXLqn9TTznBdo7Q"
  },
  "staticData": null,
  "meta": null,
  "active": false
}
