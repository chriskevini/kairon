{
  "name": "Continue_Thread",
  "nodes": [
    {
      "parameters": {
        "inputSource": "passthrough"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        0,
        400
      ],
      "id": "trigger",
      "name": "Execute Workflow Trigger"
    },
    {
      "parameters": {
        "resource": "message",
        "operation": "react",
        "guildId": {
          "__rl": true,
          "value": "={{ $json.ctx.event.guild_id }}",
          "mode": "id"
        },
        "channelId": {
          "__rl": true,
          "value": "={{ $json.ctx.event.channel_id }}",
          "mode": "id"
        },
        "messageId": "={{ $json.ctx.event.message_id }}",
        "emoji": "=ðŸ’­"
      },
      "type": "n8n-nodes-base.discord",
      "typeVersion": 2,
      "position": [
        224,
        200
      ],
      "id": "react-thinking",
      "name": "React with ðŸ’­",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 1000,
      "credentials": {
        "discordBotApi": {
          "id": "hvetTjtpeKFB1V0I",
          "name": "Discord Bot account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "method": "DELETE",
        "url": "=https://discord.com/api/v10/channels/{{ $json.ctx.event.channel_id }}/messages/{{ $json.ctx.event.message_id }}/reactions/ðŸ”µ/@me",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "discordBotApi",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        224,
        600
      ],
      "id": "remove-blue-reaction",
      "name": "Remove ðŸ”µ Reaction",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 1000,
      "credentials": {
        "discordBotApi": {
          "id": "hvetTjtpeKFB1V0I",
          "name": "Discord Bot account"
        }
      },
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// Prepare all queries for thread continuation context\nconst ctx = $json.ctx;\n\nreturn [{\n  json: {\n    ctx: {\n      ...ctx,\n      db_queries: [\n        {\n          key: 'history',\n          sql: \"SELECT timestamp, role, text FROM thread_history WHERE thread_id = $1 AND NOT (role = 'user' AND text = $2) ORDER BY timestamp ASC LIMIT 20\",\n          params: [ctx.event.thread_id, ctx.event.clean_text]\n        },\n        {\n          key: 'north_star',\n          sql: \"SELECT value FROM config WHERE key = 'north_star'\"\n        },\n        {\n          key: 'activities',\n          sql: `SELECT \n            (data->>'timestamp')::timestamptz as timestamp,\n            data->>'category' as category,\n            data->>'description' as description\n          FROM projections\n          WHERE projection_type = 'activity'\n            AND status IN ('auto_confirmed', 'confirmed')\n          ORDER BY (data->>'timestamp')::timestamptz DESC\n          LIMIT 20`\n        },\n        {\n          key: 'notes',\n          sql: `SELECT \n            (data->>'timestamp')::timestamptz as timestamp,\n            data->>'category' as category,\n            data->>'text' as text\n          FROM projections\n          WHERE projection_type = 'note'\n            AND status IN ('auto_confirmed', 'confirmed')\n          ORDER BY (data->>'timestamp')::timestamptz DESC\n          LIMIT 10`\n        }\n      ],\n      llm: {\n        inference_start: Date.now()\n      }\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        224,
        400
      ],
      "id": "prepare-queries",
      "name": "Prepare All Queries"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "UpiUvzlgVuMdYsnp",
          "mode": "id"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "ctx": "={{ $json.ctx }}"
          }
        },
        "options": {
          "waitForSubWorkflow": true
        }
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        448,
        400
      ],
      "id": "query-db",
      "name": "Query DB"
    },
    {
      "parameters": {
        "jsCode": "// Build LLM context from batch query results\nconst ctx = $json.ctx;\n\n// Extract results from ctx.db (keyed by query name)\nconst history = (ctx.db?.history?.results || []).map(h => ({ role: h.role, text: h.text }));\nconst northStar = ctx.db?.north_star?.results?.[0]?.value || '(not set)';\nconst activities = (ctx.db?.activities?.results || []).map(a => ({\n  timestamp: a.timestamp,\n  category: a.category,\n  description: a.description\n}));\nconst notes = (ctx.db?.notes?.results || []).map(n => ({\n  timestamp: n.timestamp,\n  category: n.category,\n  text: n.text\n}));\n\nreturn [{\n  json: {\n    ctx: {\n      ...ctx,\n      llm: {\n        ...ctx.llm,\n        history: history,\n        north_star: northStar,\n        activities: activities,\n        notes: notes\n      }\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        672,
        400
      ],
      "id": "build-context",
      "name": "Build LLM Context"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are an AI life coach helping the user reflect, plan, and think deeply.\n\n## Context Available\n\n**User's Guiding Principle:** {{ $json.ctx.llm.north_star }}\n\nKeep this in mind when helping them, but don't mention it unless directly relevant to the conversation.\n\n**Recent Activities (Last 20)**\n{{ $json.ctx.llm.activities.map(act => `${DateTime.fromISO(act.timestamp).format(\"yyyy-MM-dd hh:mm\")} - ${act.description}`).join('\\n') }}\n\n**Recent Notes (Last 10)**\n{{ $json.ctx.llm.notes.map(n => `[${n.category}] ${n.text}`).join('\\n') }}\n\n## Instructions\n\n1. **Consider the full context**: conversation history, activities, and notes\n2. **Provide grounded insights**: Reference specific activities or notes when relevant\n3. **Be conversational**: This is an ongoing dialogue, not a new conversation\n4. **Ask clarifying questions**: Help them think deeper when appropriate\n5. **Be concise**: 3-5 sentences, respect their time\n6. **Don't force connections**: Only mention the guiding principle if it's naturally relevant to what they're asking about\n\n## Style\n- Warm and supportive\n- Natural and conversational\n- Focus on what they're asking, not on fitting everything into a grand narrative\n\n## Conversation History\n{{ $json.ctx.llm.history.map(msg => `${msg.role.toUpperCase()}: ${msg.text}`).join('\\n\\n') }}\n\nUSER: {{ $json.ctx.event.clean_text }}\n\nASSISTANT:",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        896,
        400
      ],
      "id": "generate-response",
      "name": "Generate Response"
    },
    {
      "parameters": {
        "model": "xiaomi/mimo-v2-flash:free",
        "options": {
          "temperature": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        904,
        624
      ],
      "id": "mimo-v2-flash",
      "name": "mimo-v2-flash",
      "credentials": {
        "openRouterApi": {
          "id": "r79IBN16aZtPIN8T",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "model": "nvidia/nemotron-nano-9b-v2:free",
        "options": {
          "temperature": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        1032,
        624
      ],
      "id": "nemotron-nano-9b",
      "name": "nemotron-nano-9b",
      "credentials": {
        "openRouterApi": {
          "id": "r79IBN16aZtPIN8T",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "llm-completion",
              "name": "ctx.llm.completion_text",
              "value": "={{ $json.text }}",
              "type": "string"
            }
          ]
        },
        "options": {
          "includeOtherFields": true
        }
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1120,
        400
      ],
      "id": "set-llm-completion",
      "name": "Set LLM Completion"
    },
    {
      "parameters": {
        "resource": "message",
        "guildId": {
          "__rl": true,
          "value": "={{ $json.ctx.event.guild_id }}",
          "mode": "id"
        },
        "channelId": {
          "__rl": true,
          "value": "={{ $json.ctx.event.thread_id }}",
          "mode": "id"
        },
        "content": "={{ $json.ctx.llm.completion_text }}",
        "options": {}
      },
      "type": "n8n-nodes-base.discord",
      "typeVersion": 2,
      "position": [
        1344,
        200
      ],
      "id": "post-to-thread",
      "name": "Post to Thread",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 1000,
      "credentials": {
        "discordBotApi": {
          "id": "hvetTjtpeKFB1V0I",
          "name": "Discord Bot account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Prepare trace data after LLM inference\nconst ctx = $json.ctx || {};\nconst response = ctx.llm?.completion_text || '';\nconst inferenceStart = ctx.llm?.inference_start || Date.now();\nconst durationMs = Date.now() - inferenceStart;\n\n// Build filled prompt (reconstructed from template)\nconst promptText = `You are an AI life coach helping the user reflect, plan, and think deeply.\n\n## Context Available\n\n**User's Guiding Principle:** ${ctx.llm?.north_star || '(not set)'}\n\n**Recent Activities (Last 20)**\n${(ctx.llm?.activities || []).map(act => `${act.timestamp} - ${act.description}`).join('\\n')}\n\n**Recent Notes (Last 10)**\n${(ctx.llm?.notes || []).map(n => `[${n.category}] ${n.text}`).join('\\n')}\n\n## Conversation History\n${(ctx.llm?.history || []).map(msg => `${msg.role.toUpperCase()}: ${msg.text}`).join('\\n\\n')}\n\nUSER: ${ctx.event?.clean_text || ''}\n\nASSISTANT:`;\n\n// Format trace_chain for PostgreSQL uuid[] type\nconst traceChain = ctx.event?.trace_chain || [];\nconst traceChainPg = '{' + traceChain.join(',') + '}';\n\nreturn [{\n  json: {\n    ctx: ctx,\n    input_text: ctx.event?.clean_text || '',\n    input_thread_id: ctx.event?.thread_id,\n    input_history_length: (ctx.llm?.history || []).length,\n    prompt_text: promptText,\n    completion_text: response,\n    result_response_length: response.length,\n    result_referenced_activities: (ctx.llm?.activities || []).length,\n    result_referenced_notes: (ctx.llm?.notes || []).length,\n    duration_ms: durationMs,\n    event_id: ctx.event?.event_id,\n    trace_chain_pg: traceChainPg\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1344,
        400
      ],
      "id": "prepare-trace-data",
      "name": "Prepare Trace Data"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "WITH new_trace AS (\n  INSERT INTO traces (event_id, step_name, data, trace_chain)\n  VALUES (\n    $1::uuid,\n    'thread_response',\n    jsonb_build_object(\n      'input', jsonb_build_object(\n        'text', $2,\n        'thread_id', $3::text,\n        'history_length', $4::integer\n      ),\n      'prompt', $5,\n      'completion', $6,\n      'result', jsonb_build_object(\n        'response_length', $7::integer,\n        'referenced_activities', $8::integer,\n        'referenced_notes', $9::integer\n      ),\n      'model', 'xiaomi/mimo-v2-flash:free',\n      'duration_ms', $10::integer\n    ),\n    $11::uuid[]\n  )\n  RETURNING id\n)\nSELECT \n  new_trace.id as trace_id,\n  $11::uuid[] || new_trace.id as updated_trace_chain\nFROM new_trace;",
        "options": {
          "queryReplacement": "={{ $json.event_id }},={{ $json.input_text }},={{ $json.input_thread_id }},={{ $json.input_history_length }},={{ $json.prompt_text }},={{ $json.completion_text }},={{ $json.result_response_length }},={{ $json.result_referenced_activities }},={{ $json.result_referenced_notes }},={{ $json.duration_ms }},={{ $json.trace_chain_pg }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [
        1568,
        400
      ],
      "id": "write-trace",
      "name": "Write Thread Response Trace",
      "credentials": {
        "postgres": {
          "id": "MdnYzEgjzWRujz2v",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        1792,
        400
      ],
      "id": "merge-trace-result",
      "name": "Merge Trace Result"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO projections (\n  event_id,\n  trace_id,\n  trace_chain,\n  projection_type,\n  status,\n  data,\n  timezone\n)\nVALUES (\n  $1::uuid,\n  $2::uuid,\n  $3::uuid[],\n  'thread_response',\n  'auto_confirmed',\n  jsonb_build_object(\n    'thread_id', $4,\n    'response_text', $5,\n    'role', 'assistant',\n    'timestamp', $6::timestamptz\n  ),\n  $7\n)\nRETURNING id;",
        "options": {
          "queryReplacement": "={{ $json.event_id }},={{ $json.trace_id }},={{ $json.updated_trace_chain }},={{ $json.ctx.event.thread_id }},={{ $json.ctx.llm.completion_text }},={{ $json.ctx.event.timestamp }},={{ $json.ctx.event.timezone }}"
        }
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [
        2016,
        400
      ],
      "id": "store-projection",
      "name": "Store Response Projection",
      "credentials": {
        "postgres": {
          "id": "MdnYzEgjzWRujz2v",
          "name": "Postgres account"
        }
      }
    }
  ],
  "connections": {
    "Execute Workflow Trigger": {
      "main": [
        [
          {
            "node": "React with ðŸ’­",
            "type": "main",
            "index": 0
          },
          {
            "node": "Prepare All Queries",
            "type": "main",
            "index": 0
          },
          {
            "node": "Remove ðŸ”µ Reaction",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare All Queries": {
      "main": [
        [
          {
            "node": "Query DB",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query DB": {
      "main": [
        [
          {
            "node": "Build LLM Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build LLM Context": {
      "main": [
        [
          {
            "node": "Generate Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Response": {
      "main": [
        [
          {
            "node": "Set LLM Completion",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "mimo-v2-flash": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Response",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "nemotron-nano-9b": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Response",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Set LLM Completion": {
      "main": [
        [
          {
            "node": "Post to Thread",
            "type": "main",
            "index": 0
          },
          {
            "node": "Prepare Trace Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Trace Data": {
      "main": [
        [
          {
            "node": "Write Thread Response Trace",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge Trace Result",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Write Thread Response Trace": {
      "main": [
        [
          {
            "node": "Merge Trace Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Trace Result": {
      "main": [
        [
          {
            "node": "Store Response Projection",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "availableInMCP": false,
    "errorWorkflow": "JOXLqn9TTznBdo7Q"
  },
  "staticData": null,
  "meta": null,
  "active": false
}
